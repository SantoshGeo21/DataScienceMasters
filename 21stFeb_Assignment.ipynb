{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95d34e-c74b-4d60-9f03-e95b5555a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.1 Ans:-\n",
    "'''\n",
    "Web scraping is the automated process of extracting data from websites. It involves using software tools to collect and \n",
    "analyze data from the internet.It is further extracted in the desirable format.\n",
    "\n",
    "Web scraping is used for various purposes, including:\n",
    "\n",
    "Business Intelligence: \n",
    "Research and Analysis:\n",
    "Marketing:\n",
    "\n",
    "Three areas where web scraping is commonly used to get data include:\n",
    "\n",
    "a.)E-commerce: Web scraping can be used to collect data on product pricing, reviews, and availability from e-commerce \n",
    "websites.\n",
    "\n",
    "b.)Social Media: Web scraping can be used to collect data on user behavior, preferences, and interactions from social media \n",
    "platforms.\n",
    "\n",
    "c.)Job Postings: Web scraping can be used to collect data on job postings, including job titles, company names, and job \n",
    "descriptions from various job listing websites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347c37c-32d2-46d6-b317-dcc0f5a07f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2 Ans:-\n",
    "'''\n",
    "There are various methods and techniques used for web scraping. Here are some of the most common methods:\n",
    "\n",
    "Parsing HTML: This involves using HTML parsers like Beautiful Soup, lxml, and html5lib to extract data from HTML pages. \n",
    "HTML tags and attributes are used to locate the data.\n",
    "\n",
    "Using APIs: Many websites offer APIs (Application Programming Interfaces) that allow developers to access and extract \n",
    "data in a structured format. APIs are often easier to use and more reliable than web scraping.\n",
    "\n",
    "Using automated browser tools: This involves using browser automation tools like Selenium, Puppeteer, and Playwright to \n",
    "automate interactions with websites and extract data.\n",
    "\n",
    "Reverse engineering APIs: In some cases, websites do not have official APIs, but it is still possible to reverse engineer\n",
    "their APIs by examining network traffic and reverse-engineering the data format.\n",
    "\n",
    "Using specialized web scraping tools: There are many web scraping tools available, such as Scrapy, Octoparse, and \n",
    "ParseHub, that offer a graphical user interface (GUI) for setting up web scraping tasks.\n",
    "\n",
    "Manual copying and pasting: This method involves manually copying and pasting data from websites into a spreadsheet or \n",
    "other data storage format. It is the least automated and most time-consuming method, but it can be useful for small-scale\n",
    "scraping tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819364a-0942-4bb2-824a-76de9b23cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.3 Ans:-\n",
    "'''\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes. It is designed for parsing HTML and XML \n",
    "documents and provides a simple interface for navigating and searching the parse tree.\n",
    "\n",
    "Some of the key features of Beautiful Soup include:\n",
    "\n",
    "i).Robust parser: Beautiful Soup can handle poorly formatted HTML and XML documents and still extract the relevant data.\n",
    "\n",
    "ii).Easy navigation: Beautiful Soup provides a simple interface for navigating and searching the parse tree.\n",
    "\n",
    "iii).Tag and attribute searching: Beautiful Soup allows you to search for data based on specific HTML or XML tags and \n",
    "attributes.\n",
    "\n",
    "iv).Integration with other Python libraries: Beautiful Soup can be easily integrated with other Python libraries such as \n",
    "requests for downloading web pages and pandas for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b861e94-6439-4326-87d3-d8e33ac08174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.4 Ans:-\n",
    "'''\n",
    "Flask is a lightweight framework to build websites.\n",
    "These can be used to scrap data and display all data on the go.\n",
    "Flask is highly flexible and can be customized to meet the specific needs of a web scraping project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0568e1-00d4-418e-9299-1fea91f6bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.5 Ans:-\n",
    "'''\n",
    "\"AWS Elastic Beanstalk\" is a fully-managed service offered by Amazon Web Services (AWS) that makes it easy to deploy and \n",
    "manage web applications in the cloud. With Elastic Beanstalk, we can upload our code and Elastic Beanstalk will\n",
    "automatically handle the deployment, scaling, and management of the application.\n",
    "\n",
    "\"AWS CodePipeline\" is a fully-managed continuous delivery service that automates the release process for software \n",
    "applications. It allows us to build, test, and deploy code changes quickly and easily."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
